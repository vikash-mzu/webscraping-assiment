{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb345de8-6a83-422c-9249-c498c6a1b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Web Scraping is the process of automatically extracting data from websites. It involves fetching web pages and extracting relevant information from them, usually through code or scripts.\n",
    "\n",
    "Why is it Used?\n",
    "\n",
    "To collect data from websites that do not provide APIs or data feeds.\n",
    "To aggregate information from multiple sources for analysis or reporting.\n",
    "To automate the extraction of large amounts of data for research or business intelligence.\n",
    "Three Areas Where Web Scraping is Used:\n",
    "\n",
    "Market Research: Collecting product prices, reviews, and other data from e-commerce sites to analyze market trends and competitor strategies.\n",
    "Real Estate: Extracting property listings, prices, and details from real estate websites for comparison and analysis.\n",
    "Job Listings: Gathering job postings and company information from job boards and career websites to track employment trends and job market opportunities.\n",
    "\n",
    "    \n",
    "Q2. What are the Different Methods Used for Web Scraping?\n",
    "Different Methods for Web Scraping:\n",
    "\n",
    "HTML Parsing: Using libraries or tools to parse the HTML content of web pages to extract data. Examples include Beautiful Soup and lxml.\n",
    "Web Crawling: Automatically navigating through multiple web pages to extract data. This often involves using spiders or bots that follow links.\n",
    "API Access: When available, accessing data through APIs provided by websites instead of scraping HTML. APIs provide structured data in formats like JSON or XML.\n",
    "Browser Automation: Using tools like Selenium to interact with web pages and extract data, especially when dealing with dynamic content loaded by JavaScript.\n",
    "\n",
    "    \n",
    "Q3. What is Beautiful Soup? Why is it Used?\n",
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. It creates a parse tree from the HTML content, which makes it easy to navigate and search the document structure.\n",
    "\n",
    "Why is it Used?\n",
    "\n",
    "Ease of Use: Provides a simple API to navigate and search HTML documents.\n",
    "Handling Different HTML Structures: Can handle poorly formatted or broken HTML.\n",
    "Integration: Works well with other libraries like requests to fetch web pages and extract data.\n",
    "\n",
    "    \n",
    "\n",
    "Q4. Why is Flask Used in This Web Scraping Project?\n",
    "Flask is a micro web framework for Python used to build web applications. In a web scraping project, Flask might be used for:\n",
    "\n",
    "Building a Web Interface: Creating a web-based interface to interact with the web scraping tool, allowing users to start scraping tasks and view results.\n",
    "Serving Scraped Data: Providing a web service to display or share the scraped data.\n",
    "Scheduling and Automation: Implementing endpoints to trigger scraping tasks or manage scraping jobs through a web application.\n",
    "\n",
    "    \n",
    "\n",
    "Q5. Write the Names of AWS Services Used in This Project. Also, Explain the Use of Each Service.\n",
    "AWS Services for Web Scraping Projects:\n",
    "\n",
    "Amazon EC2 (Elastic Compute Cloud): Provides scalable virtual servers to run web scraping scripts and handle large-scale data extraction tasks.\n",
    "Amazon S3 (Simple Storage Service): Used for storing large volumes of scraped data, such as files or databases.\n",
    "Amazon RDS (Relational Database Service) or Amazon DynamoDB: Used for storing structured or semi-structured data extracted from web scraping.\n",
    "AWS Lambda: Allows running serverless functions to automate tasks, such as periodic scraping or processing data.\n",
    "Amazon CloudWatch: Monitors and manages the performance of web scraping applications, logging, and setting up alerts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
